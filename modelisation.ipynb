{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DhekerKacem/FuturVisionTransport/blob/main/modelisation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PI-WoMtqTZmI",
        "outputId": "ff6971d5-8460-4d8b-eddd-d63fb4febeb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imgaug in /usr/local/lib/python3.10/dist-packages (0.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from imgaug) (1.16.0)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.10/dist-packages (from imgaug) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from imgaug) (1.11.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from imgaug) (9.4.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from imgaug) (3.7.1)\n",
            "Requirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.10/dist-packages (from imgaug) (0.19.3)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from imgaug) (4.8.0.76)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (from imgaug) (2.31.6)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.10/dist-packages (from imgaug) (2.0.4)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.14.2->imgaug) (3.3)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.14.2->imgaug) (2024.5.10)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.14.2->imgaug) (1.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.14.2->imgaug) (24.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug) (2.8.2)\n"
          ]
        }
      ],
      "source": [
        "pip install imgaug"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "dpHnz04ZT3oi",
        "outputId": "2df81cfe-5488-4ada-8962-80c0a7b31f5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    131\u001b[0m   )\n\u001b[1;32m    132\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chargement des biblioth√®ques"
      ],
      "metadata": {
        "id": "GgFjlfESorHO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from tensorflow.keras.utils import Sequence, to_categorical\n",
        "import imgaug as ia\n",
        "from imgaug import augmenters as iaa\n",
        "from imgaug.augmentables.segmaps import SegmentationMapsOnImage\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Dropout, Conv2DTranspose, Lambda\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "from tensorflow.keras import backend as K"
      ],
      "metadata": {
        "id": "8WTplwtOT33w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### D√©finition de la m√©trique personnalis√©e"
      ],
      "metadata": {
        "id": "v0OjtLIIovta"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomMeanIoU(tf.keras.metrics.Metric):\n",
        "    def __init__(self, name='mean_iou', num_classes=8, **kwargs):\n",
        "        super(CustomMeanIoU, self).__init__(name=name, **kwargs)\n",
        "        self.num_classes = num_classes\n",
        "        self.total_iou = self.add_weight(name='total_iou', initializer='zeros')\n",
        "        self.count_classes = self.add_weight(name='count_classes', initializer='zeros')\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        if len(y_true.shape) == 4:\n",
        "            y_true = tf.argmax(y_true, axis=-1)\n",
        "            y_pred = tf.argmax(y_pred, axis=-1)\n",
        "\n",
        "        mean_iou = 0.0\n",
        "        class_count = 0.0\n",
        "\n",
        "        for i in range(self.num_classes):\n",
        "            true_class = K.cast(K.equal(y_true, i), dtype=tf.float32)\n",
        "            pred_class = K.cast(K.equal(y_pred, i), dtype=tf.float32)\n",
        "\n",
        "            intersection = K.sum(true_class * pred_class)\n",
        "            union = K.sum(true_class) + K.sum(pred_class) - intersection\n",
        "\n",
        "            iou = intersection / (union + K.epsilon())\n",
        "            condition = K.equal(union, 0)\n",
        "            mean_iou = K.switch(condition, mean_iou, mean_iou + iou)\n",
        "            class_count = K.switch(condition, class_count, class_count + 1)\n",
        "\n",
        "        self.total_iou.assign_add(mean_iou)\n",
        "        self.count_classes.assign_add(class_count)\n",
        "\n",
        "    def result(self):\n",
        "        return self.total_iou / (self.count_classes + K.epsilon())\n",
        "\n",
        "    def reset_state(self):\n",
        "        self.total_iou.assign(0.0)\n",
        "        self.count_classes.assign(0.0)"
      ],
      "metadata": {
        "id": "aD0nqITjodLm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mod√®le Mini_Unet avec augmentation"
      ],
      "metadata": {
        "id": "EQuk5F91ohLL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### G√©n√©rateur de donn√©es"
      ],
      "metadata": {
        "id": "jmIGgJnIpW0Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DataLoadGenerator(Sequence):\n",
        "    CATS = {\n",
        "        'void': [0, 1, 2, 3, 4, 5, 6],\n",
        "        'flat': [7, 8, 9, 10],\n",
        "        'construction': [11, 12, 13, 14, 15, 16],\n",
        "        'object': [17, 18, 19, 20],\n",
        "        'nature': [21, 22],\n",
        "        'sky': [23],\n",
        "        'human': [24, 25],\n",
        "        'vehicle': [26, 27, 28, 29, 30, 31, 32, 33, -1]\n",
        "    }\n",
        "\n",
        "    def __init__(self, image_paths, mask_paths, crop_x, crop_y, batch_size, augment=False, shuffle=True):\n",
        "        \"\"\"\n",
        "        G√©n√©rateur de donn√©es avec ou sans augmentation des images\n",
        "        \"\"\"\n",
        "        self.image_paths = image_paths\n",
        "        self.mask_paths = mask_paths\n",
        "        self.crop_x = crop_x\n",
        "        self.crop_y = crop_y\n",
        "        self.batch_size = batch_size\n",
        "        self.augment = augment\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.image_paths) / self.batch_size))\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        self.indexes = np.arange(len(self.image_paths))\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_x = self.image_paths[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        batch_y = self.mask_paths[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        x,y= self._prepare_data(batch_x,batch_y)\n",
        "        return x,y\n",
        "\n",
        "    def _prepare_data(self, image_paths, mask_paths):\n",
        "        x = []\n",
        "        y = []\n",
        "        for idx, (img_path, mask_path) in enumerate(zip(image_paths, mask_paths)):\n",
        "            img, mask = self._get_image_and_mask(img_path, mask_path)\n",
        "            if self.augment:\n",
        "                img, mask = self._augment_image(img, mask)\n",
        "            x.append(img)\n",
        "            y.append(mask)\n",
        "        x = np.array(x, dtype=np.float32) / 255.0\n",
        "        y = np.array(y, dtype=np.uint8)\n",
        "        y = np.expand_dims(y, axis=-1)\n",
        "        y = to_categorical(y, num_classes=8)\n",
        "        return x, y\n",
        "\n",
        "    def _get_image_and_mask(self, img_path, mask_path):\n",
        "        img = cv2.imread(img_path)\n",
        "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "        img = cv2.resize(img, (self.crop_x, self.crop_y))\n",
        "        mask = cv2.resize(mask, (self.crop_x, self.crop_y), interpolation=cv2.INTER_NEAREST)\n",
        "        mask = self._convert_mask(mask)\n",
        "        return img, mask\n",
        "\n",
        "    def _convert_mask(self, img):\n",
        "        mask = np.zeros((img.shape[0], img.shape[1], 8), dtype=np.uint8)\n",
        "        for i in range(-1, 34):\n",
        "            if i in self.CATS['void']:\n",
        "                mask[:, :, 0] = np.logical_or(mask[:, :, 0], (img == i))\n",
        "            elif i in self.CATS['flat']:\n",
        "                mask[:, :, 1] = np.logical_or(mask[:, :, 1], (img == i))\n",
        "            elif i in self.CATS['construction']:\n",
        "                mask[:, :, 2] = np.logical_or(mask[:, :, 2], (img == i))\n",
        "            elif i in self.CATS['object']:\n",
        "                mask[:, :, 3] = np.logical_or(mask[:, :, 3], (img == i))\n",
        "            elif i in self.CATS['nature']:\n",
        "                mask[:, :, 4] = np.logical_or(mask[:, :, 4], (img == i))\n",
        "            elif i in self.CATS['sky']:\n",
        "                mask[:, :, 5] = np.logical_or(mask[:, :, 5], (img == i))\n",
        "            elif i in self.CATS['human']:\n",
        "                mask[:, :, 6] = np.logical_or(mask[:, :, 6], (img == i))\n",
        "            elif i in self.CATS['vehicle']:\n",
        "                mask[:, :, 7] = np.logical_or(mask[:, :, 7], (img == i))\n",
        "        return np.argmax(mask, axis=2).astype('uint8')\n",
        "\n",
        "    def _augment_image(self, img, mask):\n",
        "        segmap = SegmentationMapsOnImage(mask, shape=img.shape)\n",
        "\n",
        "        seq = iaa.Sequential([\n",
        "            iaa.Affine(rotate=(-10, 10)),\n",
        "            iaa.GammaContrast((0.5, 2.0)),\n",
        "            iaa.Fliplr(0.5),\n",
        "            iaa.CropAndPad(px=(-10, 10)),\n",
        "            iaa.AdditiveGaussianNoise(scale=(0, 0.05*255))\n",
        "        ])\n",
        "\n",
        "        ia.seed(2)\n",
        "        img_aug, segmap_aug = seq(image=img, segmentation_maps=segmap)\n",
        "        final_img = img_aug\n",
        "        final_mask = segmap_aug.get_arr()\n",
        "\n",
        "        return final_img, final_mask\n",
        "\n",
        "# Fonction pour obtenir les chemins des images et des masques\n",
        "def get_image_and_mask_paths(image_base_dir, mask_base_dir):\n",
        "    cities = os.listdir(image_base_dir)\n",
        "    image_paths = []\n",
        "    mask_paths = []\n",
        "    for city in cities:\n",
        "        city_image_dir = os.path.join(image_base_dir, city)\n",
        "        city_mask_dir = os.path.join(mask_base_dir, city)\n",
        "        images = os.listdir(city_image_dir)\n",
        "        for img in images:\n",
        "            mask = img.replace('_leftImg8bit.png', '_gtFine_color.png')\n",
        "            mask_path = os.path.join(city_mask_dir, mask)\n",
        "            if os.path.exists(mask_path):\n",
        "                image_paths.append(os.path.join(city_image_dir, img))\n",
        "                mask_paths.append(mask_path)\n",
        "            else:\n",
        "                print(f\"Mask not found for image: {img}\")\n",
        "    print(f\"Total images loaded from {image_base_dir}: {len(image_paths)}\")\n",
        "    print(f\"Total masks loaded from {mask_base_dir}: {len(mask_paths)}\")\n",
        "    return image_paths, mask_paths\n",
        "\n",
        "# Obtenir les chemins pour l'entra√Ænement\n",
        "train_image_base_dir = '/content/drive/My Drive//data/leftImg8bit/train'\n",
        "train_mask_base_dir = '/content/drive/My Drive//data/gtFine/train'\n",
        "train_image_paths, train_mask_paths = get_image_and_mask_paths(train_image_base_dir, train_mask_base_dir)\n",
        "\n",
        "# Obtenir les chemins pour la validation\n",
        "val_image_base_dir = '/content/drive/My Drive//data/leftImg8bit/val'\n",
        "val_mask_base_dir = '/content/drive/My Drive//data/gtFine/val'\n",
        "val_image_paths, val_mask_paths = get_image_and_mask_paths(val_image_base_dir, val_mask_base_dir)\n",
        "\n",
        "# Obtenir les chemins pour le test\n",
        "test_image_base_dir = '/content/drive/My Drive/data/leftImg8bit/test'\n",
        "test_mask_base_dir = '/content/drive/My Drive//data/gtFine/test'\n",
        "test_image_paths, test_mask_paths = get_image_and_mask_paths(test_image_base_dir, test_mask_base_dir)\n",
        "\n",
        "# Cr√©ation des DataLoaders\n",
        "train_loader = DataLoadGenerator(train_image_paths, train_mask_paths, crop_x=512, crop_y=512, batch_size=8, augment=True)\n",
        "val_loader = DataLoadGenerator(val_image_paths, val_mask_paths, crop_x=512, crop_y=512, batch_size=8, augment=False, shuffle=False)\n",
        "test_loader = DataLoadGenerator(test_image_paths, test_mask_paths, crop_x=512, crop_y=512, batch_size=8, augment=False, shuffle=False)\n",
        "\n",
        "print(f\"Total batches in train_loader: {len(train_loader)}\")\n",
        "print(f\"Total batches in val_loader: {len(val_loader)}\")\n",
        "print(f\"Total batches in test_loader: {len(test_loader)}\")\n",
        "\n",
        "# Pour tester un lot de donn√©es d'entra√Ænement et afficher la forme du masque d'origine :\n",
        "x_train, y_train = train_loader[0]\n",
        "print(x_train.shape, y_train.shape)  # Affiche la forme des lots de donn√©es g√©n√©r√©s\n",
        "\n",
        "# Pour tester un lot de donn√©es de validation :\n",
        "x_val, y_val = val_loader[0]\n",
        "print(x_val.shape, y_val.shape)  # Affiche la forme des lots de donn√©es g√©n√©r√©s\n",
        "\n",
        "# Pour tester un lot de donn√©es de test :\n",
        "x_test, y_test = test_loader[0]\n",
        "print(x_test.shape, y_test.shape)  # Affiche la forme des lots de donn√©es g√©n√©r√©s"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Np5by_P2UXgw",
        "outputId": "6a687ff3-39e2-4a31-cdf9-ae7efefba9a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total images loaded from /content/drive/My Drive//data/leftImg8bit/train: 2975\n",
            "Total masks loaded from /content/drive/My Drive//data/gtFine/train: 2975\n",
            "Total images loaded from /content/drive/My Drive//data/leftImg8bit/val: 500\n",
            "Total masks loaded from /content/drive/My Drive//data/gtFine/val: 500\n",
            "Total images loaded from /content/drive/My Drive/data/leftImg8bit/test: 1525\n",
            "Total masks loaded from /content/drive/My Drive//data/gtFine/test: 1525\n",
            "Total batches in train_loader: 372\n",
            "Total batches in val_loader: 63\n",
            "Total batches in test_loader: 191\n",
            "(8, 512, 512, 3) (8, 512, 512, 8)\n",
            "(8, 512, 512, 3) (8, 512, 512, 8)\n",
            "(8, 512, 512, 3) (8, 512, 512, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Mod√®le Mini_Unet"
      ],
      "metadata": {
        "id": "cv5g7O3Fqg1T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mini_unet(input_size=(512, 512, 3), n_classes=8):\n",
        "    inputs = Input(input_size)\n",
        "    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool1)\n",
        "    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool2)\n",
        "    conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "    conv4 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool3)\n",
        "    conv4 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv4)\n",
        "\n",
        "    up1 = concatenate([UpSampling2D(size=(2, 2))(conv4), conv3], axis=-1)\n",
        "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(up1)\n",
        "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
        "\n",
        "    up2 = concatenate([UpSampling2D(size=(2, 2))(conv5), conv2], axis=-1)\n",
        "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up2)\n",
        "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
        "\n",
        "    up3 = concatenate([UpSampling2D(size=(2, 2))(conv6), conv1], axis=-1)\n",
        "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up3)\n",
        "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
        "\n",
        "    output = Conv2D(n_classes, (1, 1), activation='softmax')(conv7)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=output)\n",
        "    return model\n",
        "\n",
        "# Cr√©er le mod√®le avec input_size = (512, 512, 3)\n",
        "model = mini_unet(input_size=(512, 512, 3), n_classes=8)\n",
        "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=[CustomMeanIoU(num_classes=8)])\n",
        "\n",
        "\n",
        "# D√©finir les callbacks\n",
        "model_checkpoint = ModelCheckpoint('mini_unet_SA.weights.h5', monitor='val_loss', save_best_only=True, save_weights_only=True)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
        "\n",
        "# D√©finir steps_per_epoch et validation_steps\n",
        "# Remplacer train_loader et val_loader par vos g√©n√©rateurs de donn√©es ou DataLoader\n",
        "steps_per_epoch = len(train_loader)\n",
        "validation_steps = len(val_loader)\n",
        "\n",
        "# Assurez-vous que steps_per_epoch et validation_steps sont des entiers positifs\n",
        "if steps_per_epoch <= 0 or validation_steps <= 0:\n",
        "    raise ValueError(\"steps_per_epoch et validation_steps doivent √™tre des entiers positifs\")"
      ],
      "metadata": {
        "id": "M-kr6FnLpu-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# V√©rifier que les formes des donn√©es correspondent √† celles attendues par le mod√®le\n",
        "print(\"Forme des donn√©es d'entra√Ænement :\", x_train.shape, y_train.shape)\n",
        "print(\"Forme des donn√©es de validation :\", x_val.shape, y_val.shape)\n",
        "\n",
        "\n",
        "# Calculer le nombre de lots de donn√©es pour l'entra√Ænement et la validation\n",
        "steps_per_epoch = len(train_loader)\n",
        "validation_steps = len(val_loader)\n",
        "\n",
        "# D√©marrer l'entra√Ænement du mod√®le\n",
        "history = model.fit(\n",
        "    train_loader,\n",
        "    workers=30,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    validation_data=val_loader,\n",
        "    validation_steps=validation_steps,\n",
        "    epochs=50,\n",
        "    callbacks=[model_checkpoint, early_stopping]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2plHPeRzaKLl",
        "outputId": "576d3730-d289-40e6-ba68-27c114012717"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Forme des donn√©es d'entra√Ænement : (8, 512, 512, 3) (8, 512, 512, 8)\n",
            "Forme des donn√©es de validation : (8, 512, 512, 3) (8, 512, 512, 8)\n",
            "Epoch 1/50\n",
            "372/372 [==============================] - 144s 369ms/step - loss: 0.4814 - mean_iou: 0.2585 - val_loss: 0.3335 - val_mean_iou: 0.2440\n",
            "Epoch 2/50\n",
            "372/372 [==============================] - 139s 365ms/step - loss: 0.3187 - mean_iou: 0.2601 - val_loss: 0.3259 - val_mean_iou: 0.2440\n",
            "Epoch 3/50\n",
            "372/372 [==============================] - 139s 366ms/step - loss: 0.3111 - mean_iou: 0.2601 - val_loss: 0.3112 - val_mean_iou: 0.2440\n",
            "Epoch 4/50\n",
            "372/372 [==============================] - 139s 364ms/step - loss: 0.2937 - mean_iou: 0.2601 - val_loss: 0.3199 - val_mean_iou: 0.2440\n",
            "Epoch 5/50\n",
            "372/372 [==============================] - 138s 364ms/step - loss: 0.2806 - mean_iou: 0.2608 - val_loss: 0.3132 - val_mean_iou: 0.2440\n",
            "Epoch 6/50\n",
            "372/372 [==============================] - 139s 365ms/step - loss: 0.2704 - mean_iou: 0.2623 - val_loss: 0.2878 - val_mean_iou: 0.2854\n",
            "Epoch 7/50\n",
            "372/372 [==============================] - 139s 365ms/step - loss: 0.2492 - mean_iou: 0.2895 - val_loss: 0.2906 - val_mean_iou: 0.2971\n",
            "Epoch 8/50\n",
            "372/372 [==============================] - 139s 367ms/step - loss: 0.2404 - mean_iou: 0.3140 - val_loss: 0.2629 - val_mean_iou: 0.3119\n",
            "Epoch 9/50\n",
            "372/372 [==============================] - 142s 372ms/step - loss: 0.2568 - mean_iou: 0.2961 - val_loss: 0.2589 - val_mean_iou: 0.3198\n",
            "Epoch 10/50\n",
            "372/372 [==============================] - 140s 368ms/step - loss: 0.2306 - mean_iou: 0.3262 - val_loss: 0.2524 - val_mean_iou: 0.3188\n",
            "Epoch 11/50\n",
            "372/372 [==============================] - 139s 365ms/step - loss: 0.2174 - mean_iou: 0.3497 - val_loss: 0.2584 - val_mean_iou: 0.3068\n",
            "Epoch 12/50\n",
            "372/372 [==============================] - 139s 365ms/step - loss: 0.2114 - mean_iou: 0.3592 - val_loss: 0.2405 - val_mean_iou: 0.3266\n",
            "Epoch 13/50\n",
            "372/372 [==============================] - 139s 364ms/step - loss: 0.2031 - mean_iou: 0.3701 - val_loss: 0.2478 - val_mean_iou: 0.3228\n",
            "Epoch 14/50\n",
            "372/372 [==============================] - 138s 364ms/step - loss: 0.2014 - mean_iou: 0.3726 - val_loss: 0.2856 - val_mean_iou: 0.3382\n",
            "Epoch 15/50\n",
            "372/372 [==============================] - 139s 366ms/step - loss: 0.1915 - mean_iou: 0.3862 - val_loss: 0.2253 - val_mean_iou: 0.3547\n",
            "Epoch 16/50\n",
            "372/372 [==============================] - 139s 365ms/step - loss: 0.1831 - mean_iou: 0.3973 - val_loss: 0.2183 - val_mean_iou: 0.3640\n",
            "Epoch 17/50\n",
            "372/372 [==============================] - 138s 364ms/step - loss: 0.1801 - mean_iou: 0.4015 - val_loss: 0.2242 - val_mean_iou: 0.3570\n",
            "Epoch 18/50\n",
            "372/372 [==============================] - 139s 365ms/step - loss: 0.1709 - mean_iou: 0.4135 - val_loss: 0.2102 - val_mean_iou: 0.3852\n",
            "Epoch 19/50\n",
            "372/372 [==============================] - 139s 365ms/step - loss: 0.1685 - mean_iou: 0.4160 - val_loss: 0.1958 - val_mean_iou: 0.3882\n",
            "Epoch 20/50\n",
            "372/372 [==============================] - 138s 363ms/step - loss: 0.1695 - mean_iou: 0.4158 - val_loss: 0.2003 - val_mean_iou: 0.3887\n",
            "Epoch 21/50\n",
            "372/372 [==============================] - 138s 363ms/step - loss: 0.1616 - mean_iou: 0.4267 - val_loss: 0.2006 - val_mean_iou: 0.3954\n",
            "Epoch 22/50\n",
            "372/372 [==============================] - 141s 371ms/step - loss: 0.1559 - mean_iou: 0.4344 - val_loss: 0.1991 - val_mean_iou: 0.3883\n",
            "Epoch 23/50\n",
            "372/372 [==============================] - 139s 365ms/step - loss: 0.1492 - mean_iou: 0.4430 - val_loss: 0.1939 - val_mean_iou: 0.3715\n",
            "Epoch 24/50\n",
            "372/372 [==============================] - 139s 365ms/step - loss: 0.1460 - mean_iou: 0.4471 - val_loss: 0.1742 - val_mean_iou: 0.4094\n",
            "Epoch 25/50\n",
            "372/372 [==============================] - 138s 363ms/step - loss: 0.1404 - mean_iou: 0.4514 - val_loss: 0.1777 - val_mean_iou: 0.4119\n",
            "Epoch 26/50\n",
            "372/372 [==============================] - 139s 365ms/step - loss: 0.1396 - mean_iou: 0.4532 - val_loss: 0.1693 - val_mean_iou: 0.4197\n",
            "Epoch 27/50\n",
            "372/372 [==============================] - 139s 365ms/step - loss: 0.1372 - mean_iou: 0.4587 - val_loss: 0.1856 - val_mean_iou: 0.4206\n",
            "Epoch 28/50\n",
            "372/372 [==============================] - 138s 363ms/step - loss: 0.1342 - mean_iou: 0.4608 - val_loss: 0.1869 - val_mean_iou: 0.4125\n",
            "Epoch 29/50\n",
            "372/372 [==============================] - 138s 363ms/step - loss: 0.1315 - mean_iou: 0.4631 - val_loss: 0.1754 - val_mean_iou: 0.4048\n",
            "Epoch 30/50\n",
            "372/372 [==============================] - 138s 364ms/step - loss: 0.1332 - mean_iou: 0.4619 - val_loss: 0.1669 - val_mean_iou: 0.4196\n",
            "Epoch 31/50\n",
            "372/372 [==============================] - 139s 364ms/step - loss: 0.1259 - mean_iou: 0.4700 - val_loss: 0.1824 - val_mean_iou: 0.4119\n",
            "Epoch 32/50\n",
            "372/372 [==============================] - 139s 365ms/step - loss: 0.1274 - mean_iou: 0.4687 - val_loss: 0.1544 - val_mean_iou: 0.4174\n",
            "Epoch 33/50\n",
            "372/372 [==============================] - 138s 364ms/step - loss: 0.1229 - mean_iou: 0.4727 - val_loss: 0.1679 - val_mean_iou: 0.4162\n",
            "Epoch 34/50\n",
            "372/372 [==============================] - 138s 364ms/step - loss: 0.1185 - mean_iou: 0.4775 - val_loss: 0.1598 - val_mean_iou: 0.4125\n",
            "Epoch 35/50\n",
            "372/372 [==============================] - 139s 365ms/step - loss: 0.1193 - mean_iou: 0.4692 - val_loss: 0.1525 - val_mean_iou: 0.4342\n",
            "Epoch 36/50\n",
            "  2/372 [..............................] - ETA: 1:54 - loss: 0.2089 - mean_iou: 0.4579 "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mod√®le sans augmentation"
      ],
      "metadata": {
        "id": "ZyI5HMxHYx3v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### G√©n√©rateur de donn√©es"
      ],
      "metadata": {
        "id": "NuPIWR7Uo_zw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DataLoadGeneratorSA(Sequence):\n",
        "    CATS = {\n",
        "        'void': [0, 1, 2, 3, 4, 5, 6],\n",
        "        'flat': [7, 8, 9, 10],\n",
        "        'construction': [11, 12, 13, 14, 15, 16],\n",
        "        'object': [17, 18, 19, 20],\n",
        "        'nature': [21, 22],\n",
        "        'sky': [23],\n",
        "        'human': [24, 25],\n",
        "        'vehicle': [26, 27, 28, 29, 30, 31, 32, 33, -1]\n",
        "    }\n",
        "\n",
        "    def __init__(self, image_paths, mask_paths, crop_x, crop_y, batch_size, shuffle=True):\n",
        "        \"\"\"\n",
        "        G√©n√©rateur de donn√©es sans augmentation des images\n",
        "        \"\"\"\n",
        "        self.image_paths = image_paths\n",
        "        self.mask_paths = mask_paths\n",
        "        self.crop_x = crop_x\n",
        "        self.crop_y = crop_y\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.image_paths) / self.batch_size))\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        self.indexes = np.arange(len(self.image_paths))\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_x = self.image_paths[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        batch_y = self.mask_paths[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        x, y = self._prepare_data(batch_x, batch_y)\n",
        "        return x, y\n",
        "\n",
        "    def _prepare_data(self, image_paths, mask_paths):\n",
        "        x = []\n",
        "        y = []\n",
        "        for img_path, mask_path in zip(image_paths, mask_paths):\n",
        "            img, mask = self._get_image_and_mask(img_path, mask_path)\n",
        "            x.append(img)\n",
        "            y.append(mask)\n",
        "        x = np.array(x, dtype=np.float32) / 255.0\n",
        "        y = np.array(y, dtype=np.uint8)\n",
        "        y = np.expand_dims(y, axis=-1)\n",
        "        y = to_categorical(y, num_classes=8)\n",
        "        return x, y\n",
        "\n",
        "    def _get_image_and_mask(self, img_path, mask_path):\n",
        "        img = cv2.imread(img_path)\n",
        "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "        img = cv2.resize(img, (self.crop_x, self.crop_y))\n",
        "        mask = cv2.resize(mask, (self.crop_x, self.crop_y), interpolation=cv2.INTER_NEAREST)\n",
        "        mask = self._convert_mask(mask)\n",
        "        return img, mask\n",
        "\n",
        "    def _convert_mask(self, img):\n",
        "        mask = np.zeros((img.shape[0], img.shape[1], 8), dtype=np.uint8)\n",
        "        for i in range(-1, 34):\n",
        "            if i in self.CATS['void']:\n",
        "                mask[:, :, 0] = np.logical_or(mask[:, :, 0], (img == i))\n",
        "            elif i in self.CATS['flat']:\n",
        "                mask[:, :, 1] = np.logical_or(mask[:, :, 1], (img == i))\n",
        "            elif i in self.CATS['construction']:\n",
        "                mask[:, :, 2] = np.logical_or(mask[:, :, 2], (img == i))\n",
        "            elif i in self.CATS['object']:\n",
        "                mask[:, :, 3] = np.logical_or(mask[:, :, 3], (img == i))\n",
        "            elif i in self.CATS['nature']:\n",
        "                mask[:, :, 4] = np.logical_or(mask[:, :, 4], (img == i))\n",
        "            elif i in self.CATS['sky']:\n",
        "                mask[:, :, 5] = np.logical_or(mask[:, :, 5], (img == i))\n",
        "            elif i in self.CATS['human']:\n",
        "                mask[:, :, 6] = np.logical_or(mask[:, :, 6], (img == i))\n",
        "            elif i in self.CATS['vehicle']:\n",
        "                mask[:, :, 7] = np.logical_or(mask[:, :, 7], (img == i))\n",
        "        return np.argmax(mask, axis=2).astype('uint8')\n",
        "\n",
        "# Fonction pour obtenir les chemins des images et des masques\n",
        "def get_image_and_mask_paths(image_base_dir, mask_base_dir):\n",
        "    cities = os.listdir(image_base_dir)\n",
        "    image_paths = []\n",
        "    mask_paths = []\n",
        "    for city in cities:\n",
        "        city_image_dir = os.path.join(image_base_dir, city)\n",
        "        city_mask_dir = os.path.join(mask_base_dir, city)\n",
        "        images = os.listdir(city_image_dir)\n",
        "        for img in images:\n",
        "            mask = img.replace('_leftImg8bit.png', '_gtFine_color.png')\n",
        "            mask_path = os.path.join(city_mask_dir, mask)\n",
        "            if os.path.exists(mask_path):\n",
        "                image_paths.append(os.path.join(city_image_dir, img))\n",
        "                mask_paths.append(mask_path)\n",
        "            else:\n",
        "                print(f\"Mask not found for image: {img}\")\n",
        "    print(f\"Total images loaded from {image_base_dir}: {len(image_paths)}\")\n",
        "    print(f\"Total masks loaded from {mask_base_dir}: {len(mask_paths)}\")\n",
        "    return image_paths, mask_paths\n",
        "\n",
        "# Obtenir les chemins pour l'entra√Ænement\n",
        "train_image_base_dir = '/content/drive/My Drive//data/leftImg8bit/train'\n",
        "train_mask_base_dir = '/content/drive/My Drive//data/gtFine/train'\n",
        "train_image_paths, train_mask_paths = get_image_and_mask_paths(train_image_base_dir, train_mask_base_dir)\n",
        "\n",
        "# Obtenir les chemins pour la validation\n",
        "val_image_base_dir = '/content/drive/My Drive//data/leftImg8bit/val'\n",
        "val_mask_base_dir = '/content/drive/My Drive//data/gtFine/val'\n",
        "val_image_paths, val_mask_paths = get_image_and_mask_paths(val_image_base_dir, val_mask_base_dir)\n",
        "\n",
        "# Obtenir les chemins pour le test\n",
        "test_image_base_dir = '/content/drive/My Drive/data/leftImg8bit/test'\n",
        "test_mask_base_dir = '/content/drive/My Drive//data/gtFine/test'\n",
        "test_image_paths, test_mask_paths = get_image_and_mask_paths(test_image_base_dir, test_mask_base_dir)\n",
        "\n",
        "# Cr√©ation des DataLoaders sans augmentation\n",
        "train_loaderSA = DataLoadGeneratorSA(train_image_paths, train_mask_paths, crop_x=512, crop_y=512, batch_size=8, shuffle=True)\n",
        "val_loaderSA = DataLoadGeneratorSA(val_image_paths, val_mask_paths, crop_x=512, crop_y=512, batch_size=8, shuffle=False)\n",
        "test_loaderSA = DataLoadGeneratorSA(test_image_paths, test_mask_paths, crop_x=512, crop_y=512, batch_size=8, shuffle=False)\n",
        "\n",
        "print(f\"Total batches in train_loader: {len(train_loaderSA)}\")\n",
        "print(f\"Total batches in val_loader: {len(val_loaderSA)}\")\n",
        "print(f\"Total batches in test_loader: {len(test_loaderSA)}\")\n",
        "\n",
        "# Pour tester un lot de donn√©es d'entra√Ænement et afficher la forme du masque d'origine :\n",
        "x_train_SA, y_train_SA = train_loaderSA[0]\n",
        "print(x_train.shape, y_train.shape)  # Affiche la forme des lots de donn√©es g√©n√©r√©s\n",
        "\n",
        "# Pour tester un lot de donn√©es de validation :\n",
        "x_val_SA, y_val_SA = val_loaderSA[0]\n",
        "print(x_val.shape, y_val.shape)  # Affiche la forme des lots de donn√©es g√©n√©r√©s\n",
        "\n",
        "# Pour tester un lot de donn√©es de test :\n",
        "x_test_SA, y_test_SA = test_loaderSA[0]\n",
        "print(x_test.shape, y_test.shape)  # Affiche la forme des lots de donn√©es g√©n√©r√©s\n"
      ],
      "metadata": {
        "id": "FEolpFj1a2v_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c604de26-1c60-4ce1-ce25-f5d42d7fe69c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total images loaded from /content/drive/My Drive//data/leftImg8bit/train: 2975\n",
            "Total masks loaded from /content/drive/My Drive//data/gtFine/train: 2975\n",
            "Total images loaded from /content/drive/My Drive//data/leftImg8bit/val: 500\n",
            "Total masks loaded from /content/drive/My Drive//data/gtFine/val: 500\n",
            "Total images loaded from /content/drive/My Drive/data/leftImg8bit/test: 1525\n",
            "Total masks loaded from /content/drive/My Drive//data/gtFine/test: 1525\n",
            "Total batches in train_loader: 372\n",
            "Total batches in val_loader: 63\n",
            "Total batches in test_loader: 191\n",
            "(8, 512, 512, 3) (8, 512, 512, 8)\n",
            "(8, 512, 512, 3) (8, 512, 512, 8)\n",
            "(8, 512, 512, 3) (8, 512, 512, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Mod√®le Mini_Unet"
      ],
      "metadata": {
        "id": "O8-Si1A_pHKJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mini_unet_SA(input_size=(512, 512, 3), n_classes=8):\n",
        "    inputs = Input(input_size)\n",
        "    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool1)\n",
        "    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool2)\n",
        "    conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "    conv4 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool3)\n",
        "    conv4 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv4)\n",
        "\n",
        "    up1 = concatenate([UpSampling2D(size=(2, 2))(conv4), conv3], axis=-1)\n",
        "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(up1)\n",
        "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
        "\n",
        "    up2 = concatenate([UpSampling2D(size=(2, 2))(conv5), conv2], axis=-1)\n",
        "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up2)\n",
        "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
        "\n",
        "    up3 = concatenate([UpSampling2D(size=(2, 2))(conv6), conv1], axis=-1)\n",
        "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up3)\n",
        "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
        "\n",
        "    output = Conv2D(n_classes, (1, 1), activation='softmax')(conv7)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=output)\n",
        "    return model\n",
        "\n",
        "# Cr√©er le mod√®le avec input_size = (512, 512, 3)\n",
        "model_SA = mini_unet_SA(input_size=(512, 512, 3), n_classes=8)\n",
        "model_SA.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=[CustomMeanIoU(num_classes=8)])\n",
        "\n",
        "\n",
        "# D√©finir les callbacks\n",
        "model_checkpoint_SA = ModelCheckpoint('mini_unet_SA.weights.h5', monitor='val_loss', save_best_only=True, save_weights_only=True)\n",
        "early_stopping_SA = EarlyStopping(monitor='val_loss', patience=10)\n",
        "\n",
        "# D√©finir steps_per_epoch et validation_steps\n",
        "# Remplacer train_loader et val_loader par vos g√©n√©rateurs de donn√©es ou DataLoader\n",
        "steps_per_epoch = len(train_loader_SA)\n",
        "validation_steps = len(val_loader_SA)\n",
        "\n",
        "# Assurez-vous que steps_per_epoch et validation_steps sont des entiers positifs\n",
        "if steps_per_epoch <= 0 or validation_steps <= 0:\n",
        "    raise ValueError(\"steps_per_epoch et validation_steps doivent √™tre des entiers positifs\")"
      ],
      "metadata": {
        "id": "nKCbyJofa3K1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "2XgjxTNHXQiO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Entrainement du mod√®le"
      ],
      "metadata": {
        "id": "E6X3aYyypRv5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# V√©rifier que les formes des donn√©es correspondent √† celles attendues par le mod√®le\n",
        "print(\"Forme des donn√©es d'entra√Ænement :\", x_train_SA.shape, y_train_SA.shape)\n",
        "print(\"Forme des donn√©es de validation :\", x_val_SA.shape, y_val_SA.shape)\n",
        "print(\"Forme des donn√©es de test :\", x_test_SA.shape, y_test_SA.shape)\n",
        "\n",
        "\n",
        "# Calculer le nombre de lots de donn√©es pour l'entra√Ænement et la validation\n",
        "steps_per_epoch = len(train_loaderSA)\n",
        "validation_steps = len(val_loaderSA)\n",
        "\n",
        "# D√©marrer l'entra√Ænement du mod√®le\n",
        "history = model_SA.fit(\n",
        "    train_loaderSA,\n",
        "    workers=30,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    validation_data=val_loaderSA,\n",
        "    validation_steps=validation_steps,\n",
        "    epochs=50,\n",
        "    callbacks=[model_checkpoint_SA, early_stopping_SA]\n",
        ")"
      ],
      "metadata": {
        "id": "JgRs73QUXR3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mod√®le VGG16 sans augmentation\n"
      ],
      "metadata": {
        "id": "4MJRvpV5y8xc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def vgg16_sa(input_size=(512, 512, 3), n_classes=8):\n",
        "    inputs = Input(input_size)\n",
        "\n",
        "    # Redimensionner les images d'entr√©e √† (224, 224, 3) pour VGG16\n",
        "    resized_inputs = Lambda(lambda x: tf.image.resize(x, (224, 224)))(inputs)\n",
        "    preprocessed_inputs = preprocess_input(resized_inputs)\n",
        "\n",
        "    # Encoder (VGG16)\n",
        "    vgg16 = VGG16(include_top=False, weights='imagenet', input_tensor=inputs)\n",
        "    vgg16.trainable = False  # Freeze the VGG16 layers\n",
        "\n",
        "    block4_pool = vgg16.get_layer(\"block4_pool\").output\n",
        "    block5_conv3 = vgg16.get_layer(\"block5_conv3\").output\n",
        "\n",
        "    # Decoder\n",
        "    up1 = Conv2DTranspose(512, (3, 3), strides=(2, 2), padding='same')(block5_conv3)\n",
        "    up1 = Conv2D(512, (3, 3), activation='relu', padding='same')(up1)\n",
        "\n",
        "    # Redimensionnement du block4_pool pour correspondre √† up1\n",
        "    block4_pool_resized =  Lambda(lambda x: tf.image.resize(x, (up1.shape[1], up1.shape[2])))(block4_pool)\n",
        "    up1 = concatenate([up1, block4_pool_resized], axis=-1)\n",
        "\n",
        "    up2 = Conv2DTranspose(256, (3, 3), strides=(2, 2), padding='same')(up1)\n",
        "    up2 = Conv2D(256, (3, 3), activation='relu', padding='same')(up2)\n",
        "\n",
        "    up3 = Conv2DTranspose(128, (3, 3), strides=(2, 2), padding='same')(up2)\n",
        "    up3 = Conv2D(128, (3, 3), activation='relu', padding='same')(up3)\n",
        "\n",
        "    up4 = Conv2DTranspose(64, (3, 3), strides=(2, 2), padding='same')(up3)\n",
        "    up4 = Conv2D(64, (3, 3), activation='relu', padding='same')(up4)\n",
        "\n",
        "    up5 = Conv2DTranspose(32, (3, 3), strides=(2, 2), padding='same')(up4)\n",
        "    up5 = Conv2D(32, (3, 3), activation='relu', padding='same')(up5)\n",
        "\n",
        "    # Redimensionner pour revenir √† la taille d'origine (512, 512)\n",
        "    final_upsampling = Lambda(lambda x: tf.image.resize(x, (512, 512)))(up5)\n",
        "\n",
        "    output = Conv2D(n_classes, (1, 1), activation='softmax')(final_upsampling)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=output)\n",
        "    return model\n",
        "\n",
        "# Cr√©er le mod√®le avec input_size = (512, 512, 3)\n",
        "model_vgg_sa = vgg16_sa(input_size=(512, 512, 3), n_classes=8)\n",
        "model_vgg_sa.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=[CustomMeanIoU(num_classes=8)])\n",
        "\n",
        "# D√©finir les callbacks pour surveiller dice_coefficient\n",
        "model_checkpoint_vgg_sa = ModelCheckpoint('vgg16_unet.weights.h5', monitor='val_loss', save_best_only=True, save_weights_only=True)\n",
        "early_stopping_vgg_sa = EarlyStopping(monitor='val_loss', patience=10, mode='min')"
      ],
      "metadata": {
        "id": "JCQgQLpMzEUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zeoErjJU6MK2",
        "outputId": "f9356e34-c2d8-4293-a6fb-700ab9ea0e3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "116"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()"
      ],
      "metadata": {
        "id": "Qlw9UyGx6NrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8b3NP83I6RV1",
        "outputId": "967feb18-9346-4556-be4d-b14913c8fc1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# V√©rifier que les formes des donn√©es correspondent √† celles attendues par le mod√®le\n",
        "print(\"Forme des donn√©es d'entra√Ænement :\", x_train_SA.shape, y_train_SA.shape)\n",
        "print(\"Forme des donn√©es de validation :\", x_val_SA.shape, y_val_SA.shape)\n",
        "print(\"Forme des donn√©es de test :\", x_test_SA.shape, y_test_SA.shape)\n",
        "\n",
        "\n",
        "# Calculer le nombre de lots de donn√©es pour l'entra√Ænement et la validation\n",
        "steps_per_epoch = len(train_loaderSA)\n",
        "validation_steps = len(val_loaderSA)\n",
        "\n",
        "# D√©marrer l'entra√Ænement du mod√®le\n",
        "history = model_vgg_sa.fit(\n",
        "    train_loaderSA,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    validation_data=val_loaderSA,\n",
        "    validation_steps=validation_steps,\n",
        "    epochs=20,\n",
        "    callbacks=[model_checkpoint_vgg_sa, early_stopping_vgg_sa]\n",
        ")"
      ],
      "metadata": {
        "id": "8fmflIoWzZGK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8a4f35d-181e-42c5-f8c8-e188bf63de0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Forme des donn√©es d'entra√Ænement : (8, 512, 512, 3) (8, 512, 512, 8)\n",
            "Forme des donn√©es de validation : (8, 512, 512, 3) (8, 512, 512, 8)\n",
            "Forme des donn√©es de test : (8, 512, 512, 3) (8, 512, 512, 8)\n",
            "Epoch 1/20\n",
            "  1/372 [..............................] - ETA: 17:08:03 - loss: 2.0760 - mean_iou: 0.0136"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mod√®le VGG16 avec augmentation"
      ],
      "metadata": {
        "id": "ok98EGidz9PQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def vgg16(input_size=(512, 512, 3), n_classes=8):\n",
        "    inputs = Input(input_size)\n",
        "\n",
        "    # Redimensionner les images d'entr√©e √† (224, 224, 3) pour VGG16\n",
        "    resized_inputs = Lambda(lambda x: tf.image.resize(x, (224, 224)))(inputs)\n",
        "    preprocessed_inputs = preprocess_input(resized_inputs)\n",
        "\n",
        "    # Encoder (VGG16)\n",
        "    vgg16 = VGG16(include_top=False, weights='imagenet', input_tensor=inputs)\n",
        "    vgg16.trainable = False  # Freeze the VGG16 layers\n",
        "\n",
        "    block4_pool = vgg16.get_layer(\"block4_pool\").output\n",
        "    block5_conv3 = vgg16.get_layer(\"block5_conv3\").output\n",
        "\n",
        "    # Decoder\n",
        "    up1 = Conv2DTranspose(512, (3, 3), strides=(2, 2), padding='same')(block5_conv3)\n",
        "    up1 = Conv2D(512, (3, 3), activation='relu', padding='same')(up1)\n",
        "\n",
        "    # Redimensionnement du block4_pool pour correspondre √† up1\n",
        "    block4_pool_resized =  Lambda(lambda x: tf.image.resize(x, (up1.shape[1], up1.shape[2])))(block4_pool)\n",
        "    up1 = concatenate([up1, block4_pool_resized], axis=-1)\n",
        "\n",
        "    up2 = Conv2DTranspose(256, (3, 3), strides=(2, 2), padding='same')(up1)\n",
        "    up2 = Conv2D(256, (3, 3), activation='relu', padding='same')(up2)\n",
        "\n",
        "    up3 = Conv2DTranspose(128, (3, 3), strides=(2, 2), padding='same')(up2)\n",
        "    up3 = Conv2D(128, (3, 3), activation='relu', padding='same')(up3)\n",
        "\n",
        "    up4 = Conv2DTranspose(64, (3, 3), strides=(2, 2), padding='same')(up3)\n",
        "    up4 = Conv2D(64, (3, 3), activation='relu', padding='same')(up4)\n",
        "\n",
        "    up5 = Conv2DTranspose(32, (3, 3), strides=(2, 2), padding='same')(up4)\n",
        "    up5 = Conv2D(32, (3, 3), activation='relu', padding='same')(up5)\n",
        "\n",
        "    # Redimensionner pour revenir √† la taille d'origine (512, 512)\n",
        "    final_upsampling = Lambda(lambda x: tf.image.resize(x, (512, 512)))(up5)\n",
        "\n",
        "    output = Conv2D(n_classes, (1, 1), activation='softmax')(final_upsampling)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=output)\n",
        "    return model\n",
        "\n",
        "# Cr√©er le mod√®le avec input_size = (512, 512, 3)\n",
        "model_vgg = vgg16(input_size=(512, 512, 3), n_classes=8)\n",
        "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=[CustomMeanIoU(num_classes=8)])\n",
        "\n",
        "# D√©finir les callbacks pour surveiller dice_coefficient\n",
        "model_checkpoint_vgg = ModelCheckpoint('vgg16_unet.weights.h5', monitor='val_loss', save_best_only=True, save_weights_only=True)\n",
        "early_stopping_vgg = EarlyStopping(monitor='val_loss', patience=10, mode='min')"
      ],
      "metadata": {
        "id": "hGDrWsAT0EHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# V√©rifier que les formes des donn√©es correspondent √† celles attendues par le mod√®le\n",
        "print(\"Forme des donn√©es d'entra√Ænement :\", x_train.shape, y_train.shape)\n",
        "print(\"Forme des donn√©es de validation :\", x_val.shape, y_val.shape)\n",
        "print(\"Forme des donn√©es de test :\", x_test.shape, y_test.shape)\n",
        "\n",
        "\n",
        "# Calculer le nombre de lots de donn√©es pour l'entra√Ænement et la validation\n",
        "steps_per_epoch = len(train_loader)\n",
        "validation_steps = len(val_loader)\n",
        "\n",
        "# D√©marrer l'entra√Ænement du mod√®le\n",
        "history = model_vgg.fit(\n",
        "    train_loader,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    validation_data=val_loader,\n",
        "    validation_steps=validation_steps,\n",
        "    epochs=20,\n",
        "    callbacks=[model_checkpoint_vgg, early_stopping_vgg]\n",
        ")"
      ],
      "metadata": {
        "id": "4O-IPd5C9GOs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}