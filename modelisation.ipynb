{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DhekerKacem/FuturVisionTransport/blob/main/modelisation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PI-WoMtqTZmI",
        "outputId": "ff6971d5-8460-4d8b-eddd-d63fb4febeb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imgaug in /usr/local/lib/python3.10/dist-packages (0.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from imgaug) (1.16.0)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.10/dist-packages (from imgaug) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from imgaug) (1.11.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from imgaug) (9.4.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from imgaug) (3.7.1)\n",
            "Requirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.10/dist-packages (from imgaug) (0.19.3)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from imgaug) (4.8.0.76)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (from imgaug) (2.31.6)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.10/dist-packages (from imgaug) (2.0.4)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.14.2->imgaug) (3.3)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.14.2->imgaug) (2024.5.10)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.14.2->imgaug) (1.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.14.2->imgaug) (24.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug) (2.8.2)\n"
          ]
        }
      ],
      "source": [
        "pip install imgaug"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "dpHnz04ZT3oi",
        "outputId": "2df81cfe-5488-4ada-8962-80c0a7b31f5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    131\u001b[0m   )\n\u001b[1;32m    132\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chargement des bibliothèques"
      ],
      "metadata": {
        "id": "GgFjlfESorHO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from tensorflow.keras.utils import Sequence, to_categorical\n",
        "import imgaug as ia\n",
        "from imgaug import augmenters as iaa\n",
        "from imgaug.augmentables.segmaps import SegmentationMapsOnImage\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Dropout, Conv2DTranspose, Lambda\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "from tensorflow.keras import backend as K"
      ],
      "metadata": {
        "id": "8WTplwtOT33w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Définition de la métrique personnalisée"
      ],
      "metadata": {
        "id": "v0OjtLIIovta"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomMeanIoU(tf.keras.metrics.Metric):\n",
        "    def __init__(self, name='mean_iou', num_classes=8, **kwargs):\n",
        "        super(CustomMeanIoU, self).__init__(name=name, **kwargs)\n",
        "        self.num_classes = num_classes\n",
        "        self.total_iou = self.add_weight(name='total_iou', initializer='zeros')\n",
        "        self.count_classes = self.add_weight(name='count_classes', initializer='zeros')\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        if len(y_true.shape) == 4:\n",
        "            y_true = tf.argmax(y_true, axis=-1)\n",
        "            y_pred = tf.argmax(y_pred, axis=-1)\n",
        "\n",
        "        mean_iou = 0.0\n",
        "        class_count = 0.0\n",
        "\n",
        "        for i in range(self.num_classes):\n",
        "            true_class = K.cast(K.equal(y_true, i), dtype=tf.float32)\n",
        "            pred_class = K.cast(K.equal(y_pred, i), dtype=tf.float32)\n",
        "\n",
        "            intersection = K.sum(true_class * pred_class)\n",
        "            union = K.sum(true_class) + K.sum(pred_class) - intersection\n",
        "\n",
        "            iou = intersection / (union + K.epsilon())\n",
        "            condition = K.equal(union, 0)\n",
        "            mean_iou = K.switch(condition, mean_iou, mean_iou + iou)\n",
        "            class_count = K.switch(condition, class_count, class_count + 1)\n",
        "\n",
        "        self.total_iou.assign_add(mean_iou)\n",
        "        self.count_classes.assign_add(class_count)\n",
        "\n",
        "    def result(self):\n",
        "        return self.total_iou / (self.count_classes + K.epsilon())\n",
        "\n",
        "    def reset_state(self):\n",
        "        self.total_iou.assign(0.0)\n",
        "        self.count_classes.assign(0.0)"
      ],
      "metadata": {
        "id": "aD0nqITjodLm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modèle Mini_Unet avec augmentation"
      ],
      "metadata": {
        "id": "EQuk5F91ohLL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Générateur de données"
      ],
      "metadata": {
        "id": "jmIGgJnIpW0Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DataLoadGenerator(Sequence):\n",
        "    CATS = {\n",
        "        'void': [0, 1, 2, 3, 4, 5, 6],\n",
        "        'flat': [7, 8, 9, 10],\n",
        "        'construction': [11, 12, 13, 14, 15, 16],\n",
        "        'object': [17, 18, 19, 20],\n",
        "        'nature': [21, 22],\n",
        "        'sky': [23],\n",
        "        'human': [24, 25],\n",
        "        'vehicle': [26, 27, 28, 29, 30, 31, 32, 33, -1]\n",
        "    }\n",
        "\n",
        "    def __init__(self, image_paths, mask_paths, crop_x, crop_y, batch_size, augment=False, shuffle=True):\n",
        "        \"\"\"\n",
        "        Générateur de données avec ou sans augmentation des images\n",
        "        \"\"\"\n",
        "        self.image_paths = image_paths\n",
        "        self.mask_paths = mask_paths\n",
        "        self.crop_x = crop_x\n",
        "        self.crop_y = crop_y\n",
        "        self.batch_size = batch_size\n",
        "        self.augment = augment\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.image_paths) / self.batch_size))\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        self.indexes = np.arange(len(self.image_paths))\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_x = self.image_paths[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        batch_y = self.mask_paths[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        x,y= self._prepare_data(batch_x,batch_y)\n",
        "        return x,y\n",
        "\n",
        "    def _prepare_data(self, image_paths, mask_paths):\n",
        "        x = []\n",
        "        y = []\n",
        "        for idx, (img_path, mask_path) in enumerate(zip(image_paths, mask_paths)):\n",
        "            img, mask = self._get_image_and_mask(img_path, mask_path)\n",
        "            if self.augment:\n",
        "                img, mask = self._augment_image(img, mask)\n",
        "            x.append(img)\n",
        "            y.append(mask)\n",
        "        x = np.array(x, dtype=np.float32) / 255.0\n",
        "        y = np.array(y, dtype=np.uint8)\n",
        "        y = np.expand_dims(y, axis=-1)\n",
        "        y = to_categorical(y, num_classes=8)\n",
        "        return x, y\n",
        "\n",
        "    def _get_image_and_mask(self, img_path, mask_path):\n",
        "        img = cv2.imread(img_path)\n",
        "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "        img = cv2.resize(img, (self.crop_x, self.crop_y))\n",
        "        mask = cv2.resize(mask, (self.crop_x, self.crop_y), interpolation=cv2.INTER_NEAREST)\n",
        "        mask = self._convert_mask(mask)\n",
        "        return img, mask\n",
        "\n",
        "    def _convert_mask(self, img):\n",
        "        mask = np.zeros((img.shape[0], img.shape[1], 8), dtype=np.uint8)\n",
        "        for i in range(-1, 34):\n",
        "            if i in self.CATS['void']:\n",
        "                mask[:, :, 0] = np.logical_or(mask[:, :, 0], (img == i))\n",
        "            elif i in self.CATS['flat']:\n",
        "                mask[:, :, 1] = np.logical_or(mask[:, :, 1], (img == i))\n",
        "            elif i in self.CATS['construction']:\n",
        "                mask[:, :, 2] = np.logical_or(mask[:, :, 2], (img == i))\n",
        "            elif i in self.CATS['object']:\n",
        "                mask[:, :, 3] = np.logical_or(mask[:, :, 3], (img == i))\n",
        "            elif i in self.CATS['nature']:\n",
        "                mask[:, :, 4] = np.logical_or(mask[:, :, 4], (img == i))\n",
        "            elif i in self.CATS['sky']:\n",
        "                mask[:, :, 5] = np.logical_or(mask[:, :, 5], (img == i))\n",
        "            elif i in self.CATS['human']:\n",
        "                mask[:, :, 6] = np.logical_or(mask[:, :, 6], (img == i))\n",
        "            elif i in self.CATS['vehicle']:\n",
        "                mask[:, :, 7] = np.logical_or(mask[:, :, 7], (img == i))\n",
        "        return np.argmax(mask, axis=2).astype('uint8')\n",
        "\n",
        "    def _augment_image(self, img, mask):\n",
        "        segmap = SegmentationMapsOnImage(mask, shape=img.shape)\n",
        "\n",
        "        seq = iaa.Sequential([\n",
        "            iaa.Affine(rotate=(-10, 10)),\n",
        "            iaa.GammaContrast((0.5, 2.0)),\n",
        "            iaa.Fliplr(0.5),\n",
        "            iaa.CropAndPad(px=(-10, 10)),\n",
        "            iaa.AdditiveGaussianNoise(scale=(0, 0.05*255))\n",
        "        ])\n",
        "\n",
        "        ia.seed(2)\n",
        "        img_aug, segmap_aug = seq(image=img, segmentation_maps=segmap)\n",
        "        final_img = img_aug\n",
        "        final_mask = segmap_aug.get_arr()\n",
        "\n",
        "        return final_img, final_mask\n",
        "\n",
        "# Fonction pour obtenir les chemins des images et des masques\n",
        "def get_image_and_mask_paths(image_base_dir, mask_base_dir):\n",
        "    cities = os.listdir(image_base_dir)\n",
        "    image_paths = []\n",
        "    mask_paths = []\n",
        "    for city in cities:\n",
        "        city_image_dir = os.path.join(image_base_dir, city)\n",
        "        city_mask_dir = os.path.join(mask_base_dir, city)\n",
        "        images = os.listdir(city_image_dir)\n",
        "        for img in images:\n",
        "            mask = img.replace('_leftImg8bit.png', '_gtFine_color.png')\n",
        "            mask_path = os.path.join(city_mask_dir, mask)\n",
        "            if os.path.exists(mask_path):\n",
        "                image_paths.append(os.path.join(city_image_dir, img))\n",
        "                mask_paths.append(mask_path)\n",
        "            else:\n",
        "                print(f\"Mask not found for image: {img}\")\n",
        "    print(f\"Total images loaded from {image_base_dir}: {len(image_paths)}\")\n",
        "    print(f\"Total masks loaded from {mask_base_dir}: {len(mask_paths)}\")\n",
        "    return image_paths, mask_paths\n",
        "\n",
        "# Obtenir les chemins pour l'entraînement\n",
        "train_image_base_dir = '/content/drive/My Drive//data/leftImg8bit/train'\n",
        "train_mask_base_dir = '/content/drive/My Drive//data/gtFine/train'\n",
        "train_image_paths, train_mask_paths = get_image_and_mask_paths(train_image_base_dir, train_mask_base_dir)\n",
        "\n",
        "# Obtenir les chemins pour la validation\n",
        "val_image_base_dir = '/content/drive/My Drive//data/leftImg8bit/val'\n",
        "val_mask_base_dir = '/content/drive/My Drive//data/gtFine/val'\n",
        "val_image_paths, val_mask_paths = get_image_and_mask_paths(val_image_base_dir, val_mask_base_dir)\n",
        "\n",
        "# Obtenir les chemins pour le test\n",
        "test_image_base_dir = '/content/drive/My Drive/data/leftImg8bit/test'\n",
        "test_mask_base_dir = '/content/drive/My Drive//data/gtFine/test'\n",
        "test_image_paths, test_mask_paths = get_image_and_mask_paths(test_image_base_dir, test_mask_base_dir)\n",
        "\n",
        "# Création des DataLoaders\n",
        "train_loader = DataLoadGenerator(train_image_paths, train_mask_paths, crop_x=512, crop_y=512, batch_size=8, augment=True)\n",
        "val_loader = DataLoadGenerator(val_image_paths, val_mask_paths, crop_x=512, crop_y=512, batch_size=8, augment=False, shuffle=False)\n",
        "test_loader = DataLoadGenerator(test_image_paths, test_mask_paths, crop_x=512, crop_y=512, batch_size=8, augment=False, shuffle=False)\n",
        "\n",
        "print(f\"Total batches in train_loader: {len(train_loader)}\")\n",
        "print(f\"Total batches in val_loader: {len(val_loader)}\")\n",
        "print(f\"Total batches in test_loader: {len(test_loader)}\")\n",
        "\n",
        "# Pour tester un lot de données d'entraînement et afficher la forme du masque d'origine :\n",
        "x_train, y_train = train_loader[0]\n",
        "print(x_train.shape, y_train.shape)  # Affiche la forme des lots de données générés\n",
        "\n",
        "# Pour tester un lot de données de validation :\n",
        "x_val, y_val = val_loader[0]\n",
        "print(x_val.shape, y_val.shape)  # Affiche la forme des lots de données générés\n",
        "\n",
        "# Pour tester un lot de données de test :\n",
        "x_test, y_test = test_loader[0]\n",
        "print(x_test.shape, y_test.shape)  # Affiche la forme des lots de données générés"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Np5by_P2UXgw",
        "outputId": "6a687ff3-39e2-4a31-cdf9-ae7efefba9a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total images loaded from /content/drive/My Drive//data/leftImg8bit/train: 2975\n",
            "Total masks loaded from /content/drive/My Drive//data/gtFine/train: 2975\n",
            "Total images loaded from /content/drive/My Drive//data/leftImg8bit/val: 500\n",
            "Total masks loaded from /content/drive/My Drive//data/gtFine/val: 500\n",
            "Total images loaded from /content/drive/My Drive/data/leftImg8bit/test: 1525\n",
            "Total masks loaded from /content/drive/My Drive//data/gtFine/test: 1525\n",
            "Total batches in train_loader: 372\n",
            "Total batches in val_loader: 63\n",
            "Total batches in test_loader: 191\n",
            "(8, 512, 512, 3) (8, 512, 512, 8)\n",
            "(8, 512, 512, 3) (8, 512, 512, 8)\n",
            "(8, 512, 512, 3) (8, 512, 512, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Modèle Mini_Unet"
      ],
      "metadata": {
        "id": "cv5g7O3Fqg1T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mini_unet(input_size=(512, 512, 3), n_classes=8):\n",
        "    inputs = Input(input_size)\n",
        "    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool1)\n",
        "    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool2)\n",
        "    conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "    conv4 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool3)\n",
        "    conv4 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv4)\n",
        "\n",
        "    up1 = concatenate([UpSampling2D(size=(2, 2))(conv4), conv3], axis=-1)\n",
        "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(up1)\n",
        "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
        "\n",
        "    up2 = concatenate([UpSampling2D(size=(2, 2))(conv5), conv2], axis=-1)\n",
        "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up2)\n",
        "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
        "\n",
        "    up3 = concatenate([UpSampling2D(size=(2, 2))(conv6), conv1], axis=-1)\n",
        "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up3)\n",
        "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
        "\n",
        "    output = Conv2D(n_classes, (1, 1), activation='softmax')(conv7)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=output)\n",
        "    return model\n",
        "\n",
        "# Créer le modèle avec input_size = (512, 512, 3)\n",
        "model = mini_unet(input_size=(512, 512, 3), n_classes=8)\n",
        "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=[CustomMeanIoU(num_classes=8)])\n",
        "\n",
        "\n",
        "# Définir les callbacks\n",
        "model_checkpoint = ModelCheckpoint('mini_unet_SA.weights.h5', monitor='val_loss', save_best_only=True, save_weights_only=True)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
        "\n",
        "# Définir steps_per_epoch et validation_steps\n",
        "# Remplacer train_loader et val_loader par vos générateurs de données ou DataLoader\n",
        "steps_per_epoch = len(train_loader)\n",
        "validation_steps = len(val_loader)\n",
        "\n",
        "# Assurez-vous que steps_per_epoch et validation_steps sont des entiers positifs\n",
        "if steps_per_epoch <= 0 or validation_steps <= 0:\n",
        "    raise ValueError(\"steps_per_epoch et validation_steps doivent être des entiers positifs\")"
      ],
      "metadata": {
        "id": "M-kr6FnLpu-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vérifier que les formes des données correspondent à celles attendues par le modèle\n",
        "print(\"Forme des données d'entraînement :\", x_train.shape, y_train.shape)\n",
        "print(\"Forme des données de validation :\", x_val.shape, y_val.shape)\n",
        "\n",
        "\n",
        "# Calculer le nombre de lots de données pour l'entraînement et la validation\n",
        "steps_per_epoch = len(train_loader)\n",
        "validation_steps = len(val_loader)\n",
        "\n",
        "# Démarrer l'entraînement du modèle\n",
        "history = model.fit(\n",
        "    train_loader,\n",
        "    workers=30,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    validation_data=val_loader,\n",
        "    validation_steps=validation_steps,\n",
        "    epochs=50,\n",
        "    callbacks=[model_checkpoint, early_stopping]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2plHPeRzaKLl",
        "outputId": "576d3730-d289-40e6-ba68-27c114012717"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Forme des données d'entraînement : (8, 512, 512, 3) (8, 512, 512, 8)\n",
            "Forme des données de validation : (8, 512, 512, 3) (8, 512, 512, 8)\n",
            "Epoch 1/50\n",
            "372/372 [==============================] - 144s 369ms/step - loss: 0.4814 - mean_iou: 0.2585 - val_loss: 0.3335 - val_mean_iou: 0.2440\n",
            "Epoch 2/50\n",
            "372/372 [==============================] - 139s 365ms/step - loss: 0.3187 - mean_iou: 0.2601 - val_loss: 0.3259 - val_mean_iou: 0.2440\n",
            "Epoch 3/50\n",
            "372/372 [==============================] - 139s 366ms/step - loss: 0.3111 - mean_iou: 0.2601 - val_loss: 0.3112 - val_mean_iou: 0.2440\n",
            "Epoch 4/50\n",
            "372/372 [==============================] - 139s 364ms/step - loss: 0.2937 - mean_iou: 0.2601 - val_loss: 0.3199 - val_mean_iou: 0.2440\n",
            "Epoch 5/50\n",
            "372/372 [==============================] - 138s 364ms/step - loss: 0.2806 - mean_iou: 0.2608 - val_loss: 0.3132 - val_mean_iou: 0.2440\n",
            "Epoch 6/50\n",
            "372/372 [==============================] - 139s 365ms/step - loss: 0.2704 - mean_iou: 0.2623 - val_loss: 0.2878 - val_mean_iou: 0.2854\n",
            "Epoch 7/50\n",
            "372/372 [==============================] - 139s 365ms/step - loss: 0.2492 - mean_iou: 0.2895 - val_loss: 0.2906 - val_mean_iou: 0.2971\n",
            "Epoch 8/50\n",
            "372/372 [==============================] - 139s 367ms/step - loss: 0.2404 - mean_iou: 0.3140 - val_loss: 0.2629 - val_mean_iou: 0.3119\n",
            "Epoch 9/50\n",
            "372/372 [==============================] - 142s 372ms/step - loss: 0.2568 - mean_iou: 0.2961 - val_loss: 0.2589 - val_mean_iou: 0.3198\n",
            "Epoch 10/50\n",
            "372/372 [==============================] - 140s 368ms/step - loss: 0.2306 - mean_iou: 0.3262 - val_loss: 0.2524 - val_mean_iou: 0.3188\n",
            "Epoch 11/50\n",
            "372/372 [==============================] - 139s 365ms/step - loss: 0.2174 - mean_iou: 0.3497 - val_loss: 0.2584 - val_mean_iou: 0.3068\n",
            "Epoch 12/50\n",
            "372/372 [==============================] - 139s 365ms/step - loss: 0.2114 - mean_iou: 0.3592 - val_loss: 0.2405 - val_mean_iou: 0.3266\n",
            "Epoch 13/50\n",
            "372/372 [==============================] - 139s 364ms/step - loss: 0.2031 - mean_iou: 0.3701 - val_loss: 0.2478 - val_mean_iou: 0.3228\n",
            "Epoch 14/50\n",
            "372/372 [==============================] - 138s 364ms/step - loss: 0.2014 - mean_iou: 0.3726 - val_loss: 0.2856 - val_mean_iou: 0.3382\n",
            "Epoch 15/50\n",
            "372/372 [==============================] - 139s 366ms/step - loss: 0.1915 - mean_iou: 0.3862 - val_loss: 0.2253 - val_mean_iou: 0.3547\n",
            "Epoch 16/50\n",
            "372/372 [==============================] - 139s 365ms/step - loss: 0.1831 - mean_iou: 0.3973 - val_loss: 0.2183 - val_mean_iou: 0.3640\n",
            "Epoch 17/50\n",
            "372/372 [==============================] - 138s 364ms/step - loss: 0.1801 - mean_iou: 0.4015 - val_loss: 0.2242 - val_mean_iou: 0.3570\n",
            "Epoch 18/50\n",
            "372/372 [==============================] - 139s 365ms/step - loss: 0.1709 - mean_iou: 0.4135 - val_loss: 0.2102 - val_mean_iou: 0.3852\n",
            "Epoch 19/50\n",
            "372/372 [==============================] - 139s 365ms/step - loss: 0.1685 - mean_iou: 0.4160 - val_loss: 0.1958 - val_mean_iou: 0.3882\n",
            "Epoch 20/50\n",
            "372/372 [==============================] - 138s 363ms/step - loss: 0.1695 - mean_iou: 0.4158 - val_loss: 0.2003 - val_mean_iou: 0.3887\n",
            "Epoch 21/50\n",
            "372/372 [==============================] - 138s 363ms/step - loss: 0.1616 - mean_iou: 0.4267 - val_loss: 0.2006 - val_mean_iou: 0.3954\n",
            "Epoch 22/50\n",
            "372/372 [==============================] - 141s 371ms/step - loss: 0.1559 - mean_iou: 0.4344 - val_loss: 0.1991 - val_mean_iou: 0.3883\n",
            "Epoch 23/50\n",
            "372/372 [==============================] - 139s 365ms/step - loss: 0.1492 - mean_iou: 0.4430 - val_loss: 0.1939 - val_mean_iou: 0.3715\n",
            "Epoch 24/50\n",
            "372/372 [==============================] - 139s 365ms/step - loss: 0.1460 - mean_iou: 0.4471 - val_loss: 0.1742 - val_mean_iou: 0.4094\n",
            "Epoch 25/50\n",
            "372/372 [==============================] - 138s 363ms/step - loss: 0.1404 - mean_iou: 0.4514 - val_loss: 0.1777 - val_mean_iou: 0.4119\n",
            "Epoch 26/50\n",
            "372/372 [==============================] - 139s 365ms/step - loss: 0.1396 - mean_iou: 0.4532 - val_loss: 0.1693 - val_mean_iou: 0.4197\n",
            "Epoch 27/50\n",
            "372/372 [==============================] - 139s 365ms/step - loss: 0.1372 - mean_iou: 0.4587 - val_loss: 0.1856 - val_mean_iou: 0.4206\n",
            "Epoch 28/50\n",
            "372/372 [==============================] - 138s 363ms/step - loss: 0.1342 - mean_iou: 0.4608 - val_loss: 0.1869 - val_mean_iou: 0.4125\n",
            "Epoch 29/50\n",
            "372/372 [==============================] - 138s 363ms/step - loss: 0.1315 - mean_iou: 0.4631 - val_loss: 0.1754 - val_mean_iou: 0.4048\n",
            "Epoch 30/50\n",
            "372/372 [==============================] - 138s 364ms/step - loss: 0.1332 - mean_iou: 0.4619 - val_loss: 0.1669 - val_mean_iou: 0.4196\n",
            "Epoch 31/50\n",
            "372/372 [==============================] - 139s 364ms/step - loss: 0.1259 - mean_iou: 0.4700 - val_loss: 0.1824 - val_mean_iou: 0.4119\n",
            "Epoch 32/50\n",
            "372/372 [==============================] - 139s 365ms/step - loss: 0.1274 - mean_iou: 0.4687 - val_loss: 0.1544 - val_mean_iou: 0.4174\n",
            "Epoch 33/50\n",
            "372/372 [==============================] - 138s 364ms/step - loss: 0.1229 - mean_iou: 0.4727 - val_loss: 0.1679 - val_mean_iou: 0.4162\n",
            "Epoch 34/50\n",
            "372/372 [==============================] - 138s 364ms/step - loss: 0.1185 - mean_iou: 0.4775 - val_loss: 0.1598 - val_mean_iou: 0.4125\n",
            "Epoch 35/50\n",
            "372/372 [==============================] - 139s 365ms/step - loss: 0.1193 - mean_iou: 0.4692 - val_loss: 0.1525 - val_mean_iou: 0.4342\n",
            "Epoch 36/50\n",
            "  2/372 [..............................] - ETA: 1:54 - loss: 0.2089 - mean_iou: 0.4579 "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modèle sans augmentation"
      ],
      "metadata": {
        "id": "ZyI5HMxHYx3v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Générateur de données"
      ],
      "metadata": {
        "id": "NuPIWR7Uo_zw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DataLoadGeneratorSA(Sequence):\n",
        "    CATS = {\n",
        "        'void': [0, 1, 2, 3, 4, 5, 6],\n",
        "        'flat': [7, 8, 9, 10],\n",
        "        'construction': [11, 12, 13, 14, 15, 16],\n",
        "        'object': [17, 18, 19, 20],\n",
        "        'nature': [21, 22],\n",
        "        'sky': [23],\n",
        "        'human': [24, 25],\n",
        "        'vehicle': [26, 27, 28, 29, 30, 31, 32, 33, -1]\n",
        "    }\n",
        "\n",
        "    def __init__(self, image_paths, mask_paths, crop_x, crop_y, batch_size, shuffle=True):\n",
        "        \"\"\"\n",
        "        Générateur de données sans augmentation des images\n",
        "        \"\"\"\n",
        "        self.image_paths = image_paths\n",
        "        self.mask_paths = mask_paths\n",
        "        self.crop_x = crop_x\n",
        "        self.crop_y = crop_y\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.image_paths) / self.batch_size))\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        self.indexes = np.arange(len(self.image_paths))\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_x = self.image_paths[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        batch_y = self.mask_paths[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        x, y = self._prepare_data(batch_x, batch_y)\n",
        "        return x, y\n",
        "\n",
        "    def _prepare_data(self, image_paths, mask_paths):\n",
        "        x = []\n",
        "        y = []\n",
        "        for img_path, mask_path in zip(image_paths, mask_paths):\n",
        "            img, mask = self._get_image_and_mask(img_path, mask_path)\n",
        "            x.append(img)\n",
        "            y.append(mask)\n",
        "        x = np.array(x, dtype=np.float32) / 255.0\n",
        "        y = np.array(y, dtype=np.uint8)\n",
        "        y = np.expand_dims(y, axis=-1)\n",
        "        y = to_categorical(y, num_classes=8)\n",
        "        return x, y\n",
        "\n",
        "    def _get_image_and_mask(self, img_path, mask_path):\n",
        "        img = cv2.imread(img_path)\n",
        "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "        img = cv2.resize(img, (self.crop_x, self.crop_y))\n",
        "        mask = cv2.resize(mask, (self.crop_x, self.crop_y), interpolation=cv2.INTER_NEAREST)\n",
        "        mask = self._convert_mask(mask)\n",
        "        return img, mask\n",
        "\n",
        "    def _convert_mask(self, img):\n",
        "        mask = np.zeros((img.shape[0], img.shape[1], 8), dtype=np.uint8)\n",
        "        for i in range(-1, 34):\n",
        "            if i in self.CATS['void']:\n",
        "                mask[:, :, 0] = np.logical_or(mask[:, :, 0], (img == i))\n",
        "            elif i in self.CATS['flat']:\n",
        "                mask[:, :, 1] = np.logical_or(mask[:, :, 1], (img == i))\n",
        "            elif i in self.CATS['construction']:\n",
        "                mask[:, :, 2] = np.logical_or(mask[:, :, 2], (img == i))\n",
        "            elif i in self.CATS['object']:\n",
        "                mask[:, :, 3] = np.logical_or(mask[:, :, 3], (img == i))\n",
        "            elif i in self.CATS['nature']:\n",
        "                mask[:, :, 4] = np.logical_or(mask[:, :, 4], (img == i))\n",
        "            elif i in self.CATS['sky']:\n",
        "                mask[:, :, 5] = np.logical_or(mask[:, :, 5], (img == i))\n",
        "            elif i in self.CATS['human']:\n",
        "                mask[:, :, 6] = np.logical_or(mask[:, :, 6], (img == i))\n",
        "            elif i in self.CATS['vehicle']:\n",
        "                mask[:, :, 7] = np.logical_or(mask[:, :, 7], (img == i))\n",
        "        return np.argmax(mask, axis=2).astype('uint8')\n",
        "\n",
        "# Fonction pour obtenir les chemins des images et des masques\n",
        "def get_image_and_mask_paths(image_base_dir, mask_base_dir):\n",
        "    cities = os.listdir(image_base_dir)\n",
        "    image_paths = []\n",
        "    mask_paths = []\n",
        "    for city in cities:\n",
        "        city_image_dir = os.path.join(image_base_dir, city)\n",
        "        city_mask_dir = os.path.join(mask_base_dir, city)\n",
        "        images = os.listdir(city_image_dir)\n",
        "        for img in images:\n",
        "            mask = img.replace('_leftImg8bit.png', '_gtFine_color.png')\n",
        "            mask_path = os.path.join(city_mask_dir, mask)\n",
        "            if os.path.exists(mask_path):\n",
        "                image_paths.append(os.path.join(city_image_dir, img))\n",
        "                mask_paths.append(mask_path)\n",
        "            else:\n",
        "                print(f\"Mask not found for image: {img}\")\n",
        "    print(f\"Total images loaded from {image_base_dir}: {len(image_paths)}\")\n",
        "    print(f\"Total masks loaded from {mask_base_dir}: {len(mask_paths)}\")\n",
        "    return image_paths, mask_paths\n",
        "\n",
        "# Obtenir les chemins pour l'entraînement\n",
        "train_image_base_dir = '/content/drive/My Drive//data/leftImg8bit/train'\n",
        "train_mask_base_dir = '/content/drive/My Drive//data/gtFine/train'\n",
        "train_image_paths, train_mask_paths = get_image_and_mask_paths(train_image_base_dir, train_mask_base_dir)\n",
        "\n",
        "# Obtenir les chemins pour la validation\n",
        "val_image_base_dir = '/content/drive/My Drive//data/leftImg8bit/val'\n",
        "val_mask_base_dir = '/content/drive/My Drive//data/gtFine/val'\n",
        "val_image_paths, val_mask_paths = get_image_and_mask_paths(val_image_base_dir, val_mask_base_dir)\n",
        "\n",
        "# Obtenir les chemins pour le test\n",
        "test_image_base_dir = '/content/drive/My Drive/data/leftImg8bit/test'\n",
        "test_mask_base_dir = '/content/drive/My Drive//data/gtFine/test'\n",
        "test_image_paths, test_mask_paths = get_image_and_mask_paths(test_image_base_dir, test_mask_base_dir)\n",
        "\n",
        "# Création des DataLoaders sans augmentation\n",
        "train_loaderSA = DataLoadGeneratorSA(train_image_paths, train_mask_paths, crop_x=512, crop_y=512, batch_size=8, shuffle=True)\n",
        "val_loaderSA = DataLoadGeneratorSA(val_image_paths, val_mask_paths, crop_x=512, crop_y=512, batch_size=8, shuffle=False)\n",
        "test_loaderSA = DataLoadGeneratorSA(test_image_paths, test_mask_paths, crop_x=512, crop_y=512, batch_size=8, shuffle=False)\n",
        "\n",
        "print(f\"Total batches in train_loader: {len(train_loaderSA)}\")\n",
        "print(f\"Total batches in val_loader: {len(val_loaderSA)}\")\n",
        "print(f\"Total batches in test_loader: {len(test_loaderSA)}\")\n",
        "\n",
        "# Pour tester un lot de données d'entraînement et afficher la forme du masque d'origine :\n",
        "x_train_SA, y_train_SA = train_loaderSA[0]\n",
        "print(x_train.shape, y_train.shape)  # Affiche la forme des lots de données générés\n",
        "\n",
        "# Pour tester un lot de données de validation :\n",
        "x_val_SA, y_val_SA = val_loaderSA[0]\n",
        "print(x_val.shape, y_val.shape)  # Affiche la forme des lots de données générés\n",
        "\n",
        "# Pour tester un lot de données de test :\n",
        "x_test_SA, y_test_SA = test_loaderSA[0]\n",
        "print(x_test.shape, y_test.shape)  # Affiche la forme des lots de données générés\n"
      ],
      "metadata": {
        "id": "FEolpFj1a2v_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c604de26-1c60-4ce1-ce25-f5d42d7fe69c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total images loaded from /content/drive/My Drive//data/leftImg8bit/train: 2975\n",
            "Total masks loaded from /content/drive/My Drive//data/gtFine/train: 2975\n",
            "Total images loaded from /content/drive/My Drive//data/leftImg8bit/val: 500\n",
            "Total masks loaded from /content/drive/My Drive//data/gtFine/val: 500\n",
            "Total images loaded from /content/drive/My Drive/data/leftImg8bit/test: 1525\n",
            "Total masks loaded from /content/drive/My Drive//data/gtFine/test: 1525\n",
            "Total batches in train_loader: 372\n",
            "Total batches in val_loader: 63\n",
            "Total batches in test_loader: 191\n",
            "(8, 512, 512, 3) (8, 512, 512, 8)\n",
            "(8, 512, 512, 3) (8, 512, 512, 8)\n",
            "(8, 512, 512, 3) (8, 512, 512, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Modèle Mini_Unet"
      ],
      "metadata": {
        "id": "O8-Si1A_pHKJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mini_unet_SA(input_size=(512, 512, 3), n_classes=8):\n",
        "    inputs = Input(input_size)\n",
        "    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool1)\n",
        "    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool2)\n",
        "    conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "    conv4 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool3)\n",
        "    conv4 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv4)\n",
        "\n",
        "    up1 = concatenate([UpSampling2D(size=(2, 2))(conv4), conv3], axis=-1)\n",
        "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(up1)\n",
        "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
        "\n",
        "    up2 = concatenate([UpSampling2D(size=(2, 2))(conv5), conv2], axis=-1)\n",
        "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up2)\n",
        "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
        "\n",
        "    up3 = concatenate([UpSampling2D(size=(2, 2))(conv6), conv1], axis=-1)\n",
        "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up3)\n",
        "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
        "\n",
        "    output = Conv2D(n_classes, (1, 1), activation='softmax')(conv7)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=output)\n",
        "    return model\n",
        "\n",
        "# Créer le modèle avec input_size = (512, 512, 3)\n",
        "model_SA = mini_unet_SA(input_size=(512, 512, 3), n_classes=8)\n",
        "model_SA.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=[CustomMeanIoU(num_classes=8)])\n",
        "\n",
        "\n",
        "# Définir les callbacks\n",
        "model_checkpoint_SA = ModelCheckpoint('mini_unet_SA.weights.h5', monitor='val_loss', save_best_only=True, save_weights_only=True)\n",
        "early_stopping_SA = EarlyStopping(monitor='val_loss', patience=10)\n",
        "\n",
        "# Définir steps_per_epoch et validation_steps\n",
        "# Remplacer train_loader et val_loader par vos générateurs de données ou DataLoader\n",
        "steps_per_epoch = len(train_loader_SA)\n",
        "validation_steps = len(val_loader_SA)\n",
        "\n",
        "# Assurez-vous que steps_per_epoch et validation_steps sont des entiers positifs\n",
        "if steps_per_epoch <= 0 or validation_steps <= 0:\n",
        "    raise ValueError(\"steps_per_epoch et validation_steps doivent être des entiers positifs\")"
      ],
      "metadata": {
        "id": "nKCbyJofa3K1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "2XgjxTNHXQiO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Entrainement du modèle"
      ],
      "metadata": {
        "id": "E6X3aYyypRv5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vérifier que les formes des données correspondent à celles attendues par le modèle\n",
        "print(\"Forme des données d'entraînement :\", x_train_SA.shape, y_train_SA.shape)\n",
        "print(\"Forme des données de validation :\", x_val_SA.shape, y_val_SA.shape)\n",
        "print(\"Forme des données de test :\", x_test_SA.shape, y_test_SA.shape)\n",
        "\n",
        "\n",
        "# Calculer le nombre de lots de données pour l'entraînement et la validation\n",
        "steps_per_epoch = len(train_loaderSA)\n",
        "validation_steps = len(val_loaderSA)\n",
        "\n",
        "# Démarrer l'entraînement du modèle\n",
        "history = model_SA.fit(\n",
        "    train_loaderSA,\n",
        "    workers=30,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    validation_data=val_loaderSA,\n",
        "    validation_steps=validation_steps,\n",
        "    epochs=50,\n",
        "    callbacks=[model_checkpoint_SA, early_stopping_SA]\n",
        ")"
      ],
      "metadata": {
        "id": "JgRs73QUXR3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modèle VGG16 sans augmentation\n"
      ],
      "metadata": {
        "id": "4MJRvpV5y8xc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def vgg16_sa(input_size=(512, 512, 3), n_classes=8):\n",
        "    inputs = Input(input_size)\n",
        "\n",
        "    # Redimensionner les images d'entrée à (224, 224, 3) pour VGG16\n",
        "    resized_inputs = Lambda(lambda x: tf.image.resize(x, (224, 224)))(inputs)\n",
        "    preprocessed_inputs = preprocess_input(resized_inputs)\n",
        "\n",
        "    # Encoder (VGG16)\n",
        "    vgg16 = VGG16(include_top=False, weights='imagenet', input_tensor=inputs)\n",
        "    vgg16.trainable = False  # Freeze the VGG16 layers\n",
        "\n",
        "    block4_pool = vgg16.get_layer(\"block4_pool\").output\n",
        "    block5_conv3 = vgg16.get_layer(\"block5_conv3\").output\n",
        "\n",
        "    # Decoder\n",
        "    up1 = Conv2DTranspose(512, (3, 3), strides=(2, 2), padding='same')(block5_conv3)\n",
        "    up1 = Conv2D(512, (3, 3), activation='relu', padding='same')(up1)\n",
        "\n",
        "    # Redimensionnement du block4_pool pour correspondre à up1\n",
        "    block4_pool_resized =  Lambda(lambda x: tf.image.resize(x, (up1.shape[1], up1.shape[2])))(block4_pool)\n",
        "    up1 = concatenate([up1, block4_pool_resized], axis=-1)\n",
        "\n",
        "    up2 = Conv2DTranspose(256, (3, 3), strides=(2, 2), padding='same')(up1)\n",
        "    up2 = Conv2D(256, (3, 3), activation='relu', padding='same')(up2)\n",
        "\n",
        "    up3 = Conv2DTranspose(128, (3, 3), strides=(2, 2), padding='same')(up2)\n",
        "    up3 = Conv2D(128, (3, 3), activation='relu', padding='same')(up3)\n",
        "\n",
        "    up4 = Conv2DTranspose(64, (3, 3), strides=(2, 2), padding='same')(up3)\n",
        "    up4 = Conv2D(64, (3, 3), activation='relu', padding='same')(up4)\n",
        "\n",
        "    up5 = Conv2DTranspose(32, (3, 3), strides=(2, 2), padding='same')(up4)\n",
        "    up5 = Conv2D(32, (3, 3), activation='relu', padding='same')(up5)\n",
        "\n",
        "    # Redimensionner pour revenir à la taille d'origine (512, 512)\n",
        "    final_upsampling = Lambda(lambda x: tf.image.resize(x, (512, 512)))(up5)\n",
        "\n",
        "    output = Conv2D(n_classes, (1, 1), activation='softmax')(final_upsampling)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=output)\n",
        "    return model\n",
        "\n",
        "# Créer le modèle avec input_size = (512, 512, 3)\n",
        "model_vgg_sa = vgg16_sa(input_size=(512, 512, 3), n_classes=8)\n",
        "model_vgg_sa.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=[CustomMeanIoU(num_classes=8)])\n",
        "\n",
        "# Définir les callbacks pour surveiller dice_coefficient\n",
        "model_checkpoint_vgg_sa = ModelCheckpoint('vgg16_unet.weights.h5', monitor='val_loss', save_best_only=True, save_weights_only=True)\n",
        "early_stopping_vgg_sa = EarlyStopping(monitor='val_loss', patience=10, mode='min')"
      ],
      "metadata": {
        "id": "JCQgQLpMzEUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zeoErjJU6MK2",
        "outputId": "f9356e34-c2d8-4293-a6fb-700ab9ea0e3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "116"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()"
      ],
      "metadata": {
        "id": "Qlw9UyGx6NrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8b3NP83I6RV1",
        "outputId": "967feb18-9346-4556-be4d-b14913c8fc1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vérifier que les formes des données correspondent à celles attendues par le modèle\n",
        "print(\"Forme des données d'entraînement :\", x_train_SA.shape, y_train_SA.shape)\n",
        "print(\"Forme des données de validation :\", x_val_SA.shape, y_val_SA.shape)\n",
        "print(\"Forme des données de test :\", x_test_SA.shape, y_test_SA.shape)\n",
        "\n",
        "\n",
        "# Calculer le nombre de lots de données pour l'entraînement et la validation\n",
        "steps_per_epoch = len(train_loaderSA)\n",
        "validation_steps = len(val_loaderSA)\n",
        "\n",
        "# Démarrer l'entraînement du modèle\n",
        "history = model_vgg_sa.fit(\n",
        "    train_loaderSA,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    validation_data=val_loaderSA,\n",
        "    validation_steps=validation_steps,\n",
        "    epochs=20,\n",
        "    callbacks=[model_checkpoint_vgg_sa, early_stopping_vgg_sa]\n",
        ")"
      ],
      "metadata": {
        "id": "8fmflIoWzZGK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8a4f35d-181e-42c5-f8c8-e188bf63de0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Forme des données d'entraînement : (8, 512, 512, 3) (8, 512, 512, 8)\n",
            "Forme des données de validation : (8, 512, 512, 3) (8, 512, 512, 8)\n",
            "Forme des données de test : (8, 512, 512, 3) (8, 512, 512, 8)\n",
            "Epoch 1/20\n",
            "  1/372 [..............................] - ETA: 17:08:03 - loss: 2.0760 - mean_iou: 0.0136"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modèle VGG16 avec augmentation"
      ],
      "metadata": {
        "id": "ok98EGidz9PQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def vgg16(input_size=(512, 512, 3), n_classes=8):\n",
        "    inputs = Input(input_size)\n",
        "\n",
        "    # Redimensionner les images d'entrée à (224, 224, 3) pour VGG16\n",
        "    resized_inputs = Lambda(lambda x: tf.image.resize(x, (224, 224)))(inputs)\n",
        "    preprocessed_inputs = preprocess_input(resized_inputs)\n",
        "\n",
        "    # Encoder (VGG16)\n",
        "    vgg16 = VGG16(include_top=False, weights='imagenet', input_tensor=inputs)\n",
        "    vgg16.trainable = False  # Freeze the VGG16 layers\n",
        "\n",
        "    block4_pool = vgg16.get_layer(\"block4_pool\").output\n",
        "    block5_conv3 = vgg16.get_layer(\"block5_conv3\").output\n",
        "\n",
        "    # Decoder\n",
        "    up1 = Conv2DTranspose(512, (3, 3), strides=(2, 2), padding='same')(block5_conv3)\n",
        "    up1 = Conv2D(512, (3, 3), activation='relu', padding='same')(up1)\n",
        "\n",
        "    # Redimensionnement du block4_pool pour correspondre à up1\n",
        "    block4_pool_resized =  Lambda(lambda x: tf.image.resize(x, (up1.shape[1], up1.shape[2])))(block4_pool)\n",
        "    up1 = concatenate([up1, block4_pool_resized], axis=-1)\n",
        "\n",
        "    up2 = Conv2DTranspose(256, (3, 3), strides=(2, 2), padding='same')(up1)\n",
        "    up2 = Conv2D(256, (3, 3), activation='relu', padding='same')(up2)\n",
        "\n",
        "    up3 = Conv2DTranspose(128, (3, 3), strides=(2, 2), padding='same')(up2)\n",
        "    up3 = Conv2D(128, (3, 3), activation='relu', padding='same')(up3)\n",
        "\n",
        "    up4 = Conv2DTranspose(64, (3, 3), strides=(2, 2), padding='same')(up3)\n",
        "    up4 = Conv2D(64, (3, 3), activation='relu', padding='same')(up4)\n",
        "\n",
        "    up5 = Conv2DTranspose(32, (3, 3), strides=(2, 2), padding='same')(up4)\n",
        "    up5 = Conv2D(32, (3, 3), activation='relu', padding='same')(up5)\n",
        "\n",
        "    # Redimensionner pour revenir à la taille d'origine (512, 512)\n",
        "    final_upsampling = Lambda(lambda x: tf.image.resize(x, (512, 512)))(up5)\n",
        "\n",
        "    output = Conv2D(n_classes, (1, 1), activation='softmax')(final_upsampling)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=output)\n",
        "    return model\n",
        "\n",
        "# Créer le modèle avec input_size = (512, 512, 3)\n",
        "model_vgg = vgg16(input_size=(512, 512, 3), n_classes=8)\n",
        "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=[CustomMeanIoU(num_classes=8)])\n",
        "\n",
        "# Définir les callbacks pour surveiller dice_coefficient\n",
        "model_checkpoint_vgg = ModelCheckpoint('vgg16_unet.weights.h5', monitor='val_loss', save_best_only=True, save_weights_only=True)\n",
        "early_stopping_vgg = EarlyStopping(monitor='val_loss', patience=10, mode='min')"
      ],
      "metadata": {
        "id": "hGDrWsAT0EHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vérifier que les formes des données correspondent à celles attendues par le modèle\n",
        "print(\"Forme des données d'entraînement :\", x_train.shape, y_train.shape)\n",
        "print(\"Forme des données de validation :\", x_val.shape, y_val.shape)\n",
        "print(\"Forme des données de test :\", x_test.shape, y_test.shape)\n",
        "\n",
        "\n",
        "# Calculer le nombre de lots de données pour l'entraînement et la validation\n",
        "steps_per_epoch = len(train_loader)\n",
        "validation_steps = len(val_loader)\n",
        "\n",
        "# Démarrer l'entraînement du modèle\n",
        "history = model_vgg.fit(\n",
        "    train_loader,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    validation_data=val_loader,\n",
        "    validation_steps=validation_steps,\n",
        "    epochs=20,\n",
        "    callbacks=[model_checkpoint_vgg, early_stopping_vgg]\n",
        ")"
      ],
      "metadata": {
        "id": "4O-IPd5C9GOs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}